groups:
  - name: common
    rules:

      - alert: VolumeFreeDiskSpace
        expr: round(100 - ((node_filesystem_avail_bytes{device=~".*DO_Volume_pvc.*"} * 100) / node_filesystem_size_bytes{device=~".*DO_Volume_pvc.*"})) > 90
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Volume almost full on {{ $labels.instance }}"
          description: "Node {{ $labels.instance }} attached volume {{ $labels.device }} almost full ({{ $value }}%)"

      - alert: NodeFreeDiskSpace
        expr: round(100 - ((node_filesystem_avail_bytes{device=~"/dev/vda.+", mountpoint="/"} * 100) / node_filesystem_size_bytes{device=~"/dev/vda.+", mountpoint="/"})) > 90
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Node {{ $labels.instance }} disk almost full"
          description: "Disk {{ $labels.device }} is almost full ({{ $value }}%)"

      - alert: ApiPodDown
        expr: sum(kube_pod_status_ready{namespace="cash-track", condition="true", pod=~"api.*"}) < 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: API down
          description: API service does not have enough ready pods to serve traffic for more than 5 minutes

      - alert: WebsitePodDown
        expr: sum(kube_pod_status_ready{namespace="cash-track", condition="true", pod=~"website.*"}) < 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: Website down
          description: Website service does not have enough ready pods to serve traffic for more than 5 minutes

      - alert: FrontendPodDown
        expr: sum(kube_pod_status_ready{namespace="cash-track", condition="true", pod=~"frontend.*"}) < 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: Frontend down
          description: Frontend service does not have enough ready pods to serve traffic for more than 5 minutes

      - alert: DatabasePodDown
        expr: sum(kube_pod_status_ready{namespace="cash-track", condition="true", pod="mysql-0"}) < 1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: Database down
          description: Database stateful set pod is not in ready state for more than 5 minutes

      - alert: DatabaseBackupPodDown
        expr: sum(kube_pod_status_ready{namespace="cash-track", condition="true", pod=~"mysql-backup-.*"}) < 1
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: Database down
          description: Database stateful set pod is not in ready state for more than 5 minutes

      - alert: PodScheduleFailed
        expr: sum(kube_pod_status_phase{namespace=~"telegram-bots|monitoring|ingress-nginx|cash-track", phase="Pending"}) > 1
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Pod {{ $labels.pod }} schedule failed"
          description: "Pod {{ $labels.namespace }}/{{ $labels.pod }} cannot be scheduled to any node for last 30 minutes"

      - alert: ContainerTooManyRestarts
        expr: sum by (pod, container) (changes(kube_pod_container_status_restarts_total{namespace=~"telegram-bots|monitoring|ingress-nginx|cash-track"}[5m])) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Container {{ $labels.container }} too frequently restarting"
          description: "Container {{ $labels.container }} of a pod {{ $labels.pod }} restarted more than 5 times by last 5 minutes"

      - alert: NodeHighCPURequest
        expr: (sum by (node) (kube_pod_container_resource_requests{resource="cpu"}) / sum by (node) (kube_node_status_allocatable{resource="cpu"}) * 100) > 95
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Node {{ $labels.node }} high CPU request"
          description: "Node {{ $labels.node }} is under CPU request more than 95% of allocatable resources"

      - alert: NodeHighMemoryRequest
        expr: (sum by (node) (kube_pod_container_resource_requests{resource="memory"}) / sum by (node) (kube_node_status_allocatable{resource="memory"}) * 100) > 95
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Node {{ $labels.node }} high memory request"
          description: "Node {{ $labels.node }} is under memory request more than 95% of allocatable resources"

      - alert: HTTPServiceHighServerErrorRate
        expr: round((sum by (service, method, path, status) (rate(nginx_ingress_controller_requests{service=~"api|website|frontend|crashers-bot",status=~"5.."}[2m])) / sum by (service, method, path, status) (rate(nginx_ingress_controller_requests{service=~"api|website|frontend|crashers-bot"}[2m]))) * 100) > 20
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "HTTP service {{ $labels.service }} has reached {{ $value }}% of 5xx responses rate"
          description: "Service {{ $labels.service }} responding to {{ $labels.method }} {{ $labels.path }} with HTTP status code {{ $labels.status }} for more than {{ $value }}% requests for last 5 minutes"

      - alert: HTTPServiceHighClientErrorRate
        expr: round((sum by (service, method, path, status) (rate(nginx_ingress_controller_requests{service=~"api|website|frontend|crashers-bot",status=~"4.."}[2m])) / sum by (service, method, path, status) (rate(nginx_ingress_controller_requests{service=~"api|website|frontend|crashers-bot"}[2m]))) * 100) > 80
        for: 5m
        labels:
          severity: info
        annotations:
          summary: "HTTP service {{ $labels.service }} has reached {{ $value }}% of 4xx responses rate"
          description: "Service {{ $labels.service }} responding to {{ $labels.method }} {{ $labels.path }} with HTTP status code {{ $labels.status }} for more than {{ $value }}% requests for last 5 minutes"

      - alert: HTTPServiceHighResponseLatency
        expr: histogram_quantile(0.90, sum(rate(nginx_ingress_controller_request_duration_seconds_bucket{service=~"api|website|frontend|crashers-bot"}[2m])) by (service, le, method, path)) > 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "HTTP service {{ $labels.service }} response time is high"
          description: "Service {{ $labels.service }} responds to {{ $labels.method }} {{ $labels.path }} with high latency for more than {{ $value }} seconds for last 2 minutes"


